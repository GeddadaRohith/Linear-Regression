{
 "cells": [
  {
   "cell_type": "raw",
   "id": "96f5d297-ffae-4458-b52b-1918ff03afd0",
   "metadata": {},
   "source": [
    "Write a Python script that:\n",
    "1. Use Genism to preprocess data from a sample text file, follow basic procedures like tokenization, stemming, lemmatization etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc46754d-b978-4d88-80df-7e7c3148dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccd3b60-c02d-44d5-83a4-efdcedf5a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce5e17f-9bd2-4ba3-bf63-7d19d8e966cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0528ff5d-c99d-42c3-ad99-0fb0c1b7f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in stemmed_tokens]\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986a8237-2089-4e53-a908-12a70f26db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "        return preprocess_text(text)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a4b87b-aeed-46d2-81ef-864d2b35c723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Tokens:\n",
      "['gensim', 'popular', 'python', 'librari', 'topic', 'model', 'document', 'similar', 'analysi', 'natur', 'languag', 'process', 'provid', 'robust', 'tool', 'text', 'preprocess', 'like', 'token', 'remov', 'stopword', 'strip', 'punctuat', 'stem', 'util', 'text', 'data', 'readi', 'machin', 'learn', 'nlp', 'task']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = \"sample.txt\"\n",
    "    \n",
    "    preprocessed_tokens = process_file(file_path)\n",
    "    \n",
    "    print(\"Preprocessed Tokens:\")\n",
    "    print(preprocessed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccfc01e-8aa0-458f-a71f-b044623396fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim popular python librari topic model document similar analysi natur languag process provid robust tool text preprocess like token remov stopword strip punctuat stem util text data readi machin learn nlp task\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(preprocessed_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
